{"line_number": 78, "line_type": "original", "code": "            if (result != null) {", "entropy": 0.0345458984375, "is_bug_line": false, "sus_score": 0.51512, "per_token_entropy": [0.0280609130859375, 0.03424072265625, 0.041351318359375], "tokens": [4146, 3617, 22609]}
{"line_number": 78, "line_type": "generated", "code": "            if (result!= null) {", "entropy": 0.0345458984375, "is_bug_line": false, "sus_score": 0.51512, "per_token_entropy": [0.0280609130859375, 0.03424072265625, 0.041351318359375], "tokens": [4146, 3617, 22609]}
{"line_number": 77, "line_type": "original", "code": "            final CharSequence result = lookupMap.get(subSeq);", "entropy": 0.07330322265625, "is_bug_line": true, "sus_score": 0.41754, "per_token_entropy": [0.09356689453125, 0.328369140625, 0.1427001953125, 0.0023784637451171875, 0.19970703125, 0.0184173583984375, 0.00492095947265625, 0.003803253173828125, 0.0008902549743652344, 6.449222564697266e-05, 0.01125335693359375], "tokens": [292, 8581, 3313, 45553, 3295, 9383, 2820, 5526, 773, 6230, 363]}
{"line_number": 77, "line_type": "generated", "code": "            final CharSequence result = lookupMap.get(subSeq);", "entropy": 0.07330322265625, "is_bug_line": true, "sus_score": 0.41754, "per_token_entropy": [0.09356689453125, 0.328369140625, 0.1427001953125, 0.0023784637451171875, 0.19970703125, 0.0184173583984375, 0.00492095947265625, 0.003803253173828125, 0.0008902549743652344, 6.449222564697266e-05, 0.01125335693359375], "tokens": [292, 8581, 3313, 45553, 3295, 9383, 2820, 5526, 773, 6230, 363]}
{"line_number": 75, "line_type": "original", "code": "        for (int i = max; i >= shortest; i--) {", "entropy": 0.56103515625, "is_bug_line": false, "sus_score": 0.38441, "per_token_entropy": [0.96435546875, 0.0008573532104492188, 0.311279296875, 0.6591796875, 0.0275421142578125, 0.70556640625, 2.841796875, 0.0350341796875, 0.05718994140625, 0.00762176513671875], "tokens": [1185, 7145, 4791, 1115, 23924, 2031, 41378, 702, 79, 31483]}
{"line_number": 75, "line_type": "generated", "code": "        for (final int i = shortest; i > max; i--) {", "entropy": 0.5283203125, "is_bug_line": false, "sus_score": 0.38441, "per_token_entropy": [1.5615234375, 0.703125, 0.0212249755859375, 0.345947265625, 1.2880859375, 0.8515625, 0.50390625, 0.258056640625, 0.10980224609375, 0.1632080078125, 0.006000518798828125], "tokens": [30955, 8581, 850, 4791, 41378, 23924, 512, 1115, 702, 79, 31483]}
{"line_number": 76, "line_type": "original", "code": "            final CharSequence subSeq = input.subSequence(index, index + i);", "entropy": 0.0697021484375, "is_bug_line": false, "sus_score": 0.38403, "per_token_entropy": [0.1412353515625, 0.094970703125, 0.196533203125, 0.0036678314208984375, 0.00788116455078125, 0.003917694091796875, 0.01093292236328125, 0.0154266357421875, 0.0006608963012695312, 0.0916748046875, 0.08795166015625, 0.2236328125, 0.0277099609375], "tokens": [292, 8581, 3313, 45553, 773, 6230, 275, 8511, 773, 15167, 5821, 36927, 13587]}
{"line_number": 76, "line_type": "generated", "code": "            final CharSequence subSeq = input.subSequence(index, index + i);", "entropy": 0.0697021484375, "is_bug_line": false, "sus_score": 0.38403, "per_token_entropy": [0.1412353515625, 0.094970703125, 0.196533203125, 0.0036678314208984375, 0.00788116455078125, 0.003917694091796875, 0.01093292236328125, 0.0154266357421875, 0.0006608963012695312, 0.0916748046875, 0.08795166015625, 0.2236328125, 0.0277099609375], "tokens": [292, 8581, 3313, 45553, 773, 6230, 275, 8511, 773, 15167, 5821, 36927, 13587]}
{"line_number": 71, "line_type": "original", "code": "        if (index + longest > input.length()) {", "entropy": 0.625, "is_bug_line": false, "sus_score": 0.329, "per_token_entropy": [0.09735107421875, 2.8984375, 1.380859375, -0.0, 0.56640625, 0.006015777587890625, 0.0005283355712890625, 0.051025390625], "tokens": [2192, 36927, 4036, 16510, 512, 995, 4271, 8863]}
{"line_number": 71, "line_type": "generated", "code": "        if (index < 0) {", "entropy": 0.703125, "is_bug_line": false, "sus_score": 0.329, "per_token_entropy": [0.0982666015625, 1.6171875, 0.394775390625], "tokens": [2192, 22087, 3976]}
